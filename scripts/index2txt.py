"""
Creazione di una pipeline in Pyserini per fare l'equivalente di quello che facevano loro per la submission al round 2
(BM25 sui topic del round 2 di TREC-EVAL usando la versione UDel) usando l'index full text che dia in output i top 500 hits.
"""

"""
# TODO
- index for lucene
- get queries from challange
- SimpleSearcher
# ISSUES
- not all paper have
- be sure the ids are the cord_id
# Get the data
!wget https://www.dropbox.com/s/j55t617yhvmegy8/lucene-index-covid-2020-04-10.tar.gz

!tar xvfz lucene-index-covid-2020-04-10.tar.gz

"""
# from https://github.com/gsarti/covid-papers-browser/blob/feature/TREC/trec/exploration.ipynb
import requests
import xmltodict
import json
import pprint
import pandas as pd
from pathlib import Path
from pyserini.search import pysearch
from tqdm.autonotebook import tqdm
from dataclasses import dataclass

@dataclass
class PreFetchingDocumentsWithLucene:
    queries: [str]
    searcher: pysearch.SimpleSearcher
    number_of_hits: int = 1000
    tag: str = 'covid'

    def __call__(self):
        self.query_hits = {}
        for id, query in enumerate(tqdm(self.queries)):
            # id in our case is just the number of the topics in order
            self.query_hits[query] = self.searcher.search(
                query, self.number_of_hits)
        print(f'Queries completed')

    def to_txt(self, out_path):
        with open(out_path, 'w') as runfile:
            for id, hits in enumerate(self.query_hits.values()):
                for i in range(0, len(hits)):
                    # submission format topicid Q0 docid rank score run-tag
                    _ = runfile.write('{} Q0 {} {} {:.6f} {}\n'.format(
                        id, hits[i].docid, i+1, hits[i].score, self.tag))

        print(f'Result stored at {out_path}')

    def to_metadata(self, metadata_path: Path):
        metadata = pd.read_csv(metadata_path)
        metadata['quids'] = ''
        for quid, hits in enumerate(tqdm(self.query_hits.values())):
            for i in range(len(hits)):
                docid = hits[i].docid
                # serialize array with queries ids as string of numbers
                if (metadata.cord_uid == docid).any():
                    val = metadata.loc[metadata.cord_uid ==
                                       docid, 'quids'].values[0]
                    metadata.loc[metadata.cord_uid == docid,
                                 'quids'] += f',{quid}' if val != '' else str(quid)

        metadata = metadata[metadata.quids != '']
        out_path = metadata_path.parent / metadata_path.stem
        out_path = str(out_path) + '-q.csv'
        print(f'Final shape={metadata.shape}')
        print(metadata.head(5)['quids'])
        metadata.to_csv(out_path)

        return out_path

    @classmethod
    def from_round_xml(cls, xml, *args, **kwargs):
        topic_set = xmltodict.parse(topic_set_xml)
        # [...,('query', 'coronavirus recovery'),...]
        topics = topic_set['topics']['topic']
        queries = [x['query'] for x in topics]
        return cls(queries, *args, **kwargs)


if __name__ == '__main__':
    import argparse

    parser = argparse.ArgumentParser(
        description='Create the ranking using lucene and bm25')

    parser.add_argument('--index',
                        type=str, required=True,
                        help='Path to the index files generated by lucene.')
    parser.add_argument(
        '--topics',
        type=str,
        default='https://ir.nist.gov/covidSubmit/data/topics-rnd3.xml',
        help='Url to the topics xml. The default value is the url to round 3 topics')

    parser.add_argument('--out', type=str, default=None,
                        help='Dir for the generated .txt file. By default the result will be stored using the same name as the <OUT>/<INDEX_NAME-mb25>')
    parser.add_argument('--hits', type=int, default=1000,
                        help='Number of results returned by lucene for each topic')
    parser.add_argument('--tag', type=str, default='test',
                        help='A tag for this run')

    args = parser.parse_args()
    print(f'Using index at {args.index}')
    print('Fetching topics...', end='')
    topic_set_xml = requests.get(args.topics).text
    print('done!')

    out_filepath = Path(args.out) / Path(args.index).stem
    out_filepath = str(out_filepath) + '-bm25.txt'

    searcher = pysearch.SimpleSearcher(args.index)
    pip = PreFetchingDocumentsWithLucene.from_round_xml(
        topic_set_xml, searcher, number_of_hits=args.hits, tag=args.tag)
    pip.searcher.set_bm25(0.9, 0.4)  # we should open an issue
    pip()
    # pip.to_metadata(Path('./metadata.csv'))
    pip.to_txt(out_path=out_filepath)
